[
  ["BAAI/Bunny-Llama-3-8B-V", "--load-in-4bit"],
  ["BAAI/Bunny-Llama-3-8B-V"],
  ["BAAI/Bunny-v1_0-2B-zh", "--load-in-4bit"],
  ["BAAI/Bunny-v1_0-2B-zh"],
  ["BAAI/Bunny-v1_0-3B", "--load-in-4bit"],
  ["BAAI/Bunny-v1_0-3B"],
  ["BAAI/Bunny-v1_0-3B-zh"],
  ["BAAI/Bunny-v1_0-4B", "--load-in-4bit"],
  ["BAAI/Bunny-v1_0-4B"],
  ["BAAI/Bunny-v1_1-4B", "--load-in-4bit"],
  ["BAAI/Bunny-v1_1-4B"],
  ["BAAI/Bunny-v1_1-Llama-3-8B-V", "--load-in-4bit"],
  ["BAAI/Bunny-v1_1-Llama-3-8B-V"],
  ["BAAI/Emu2-Chat", "--load-in-4bit"],
  ["BAAI/Emu2-Chat", "--max-memory=0:78GiB,1:20GiB"],
  ["HuggingFaceM4/idefics2-8b", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["HuggingFaceM4/idefics2-8b", "--use-flash-attn", "--device-map", "cuda:0"],
  ["HuggingFaceM4/idefics2-8b-AWQ", "--use-flash-attn", "--device-map", "cuda:0"],
  ["HuggingFaceM4/idefics2-8b-chatty", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["HuggingFaceM4/idefics2-8b-chatty", "--use-flash-attn", "--device-map", "cuda:0"],
  ["HuggingFaceM4/idefics2-8b-chatty-AWQ", "--use-flash-attn", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0", "--max-tiles", "40", "--load-in-4bit"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0", "--max-tiles", "40"],
  ["OpenGVLab/InternVL-Chat-V1-5", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL-Chat-V1-5-Int8", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-1B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-1B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-2B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-2B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-2B-AWQ", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-4B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-4B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-8B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-8B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-26B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-26B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-40B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/InternVL2-40B", "--device-map", "cuda:0"],
  ["OpenGVLab/InternVL2-Llama3-76B", "--device-map", "cuda:0", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5", "--max-tiles", "40", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5", "--max-tiles", "40"],
  ["OpenGVLab/Mini-InternVL-Chat-2B-V1-5"],
  ["OpenGVLab/Mini-InternVL-Chat-4B-V1-5", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-4B-V1-5", "--max-tiles", "40", "--load-in-4bit"],
  ["OpenGVLab/Mini-InternVL-Chat-4B-V1-5", "--max-tiles", "40"],
  ["OpenGVLab/Mini-InternVL-Chat-4B-V1-5"],
  ["Qwen/Qwen-VL-Chat", "--load-in-4bit"],
  ["Qwen/Qwen-VL-Chat"],
  ["Salesforce/xgen-mm-phi3-mini-instruct-r-v1"],
  ["THUDM/cogagent-chat-hf", "--load-in-4bit"],
  ["THUDM/cogagent-chat-hf"],
  ["THUDM/cogvlm-chat-hf", "--load-in-4bit"],
  ["THUDM/cogvlm-chat-hf"],
  ["THUDM/cogvlm2-llama3-chat-19B", "--load-in-4bit"],
  ["THUDM/cogvlm2-llama3-chat-19B"],
  ["THUDM/cogvlm2-llama3-chinese-chat-19B", "--load-in-4bit"],
  ["THUDM/cogvlm2-llama3-chinese-chat-19B"],
  ["THUDM/glm-4v-9b", "--device-map", "cuda:0", "--load-in-4bit"],
  ["THUDM/glm-4v-9b", "--device-map", "cuda:0"],
  ["TIGER-Lab/Mantis-8B-Fuyu", "--device-map", "cuda:0", "--load-in-4bit"],
  ["TIGER-Lab/Mantis-8B-Fuyu", "--device-map", "cuda:0"],
  ["TIGER-Lab/Mantis-8B-clip-llama3", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["TIGER-Lab/Mantis-8B-clip-llama3", "--use-flash-attn", "--device-map", "cuda:0"],
  ["TIGER-Lab/Mantis-8B-siglip-llama3", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["TIGER-Lab/Mantis-8B-siglip-llama3", "--use-flash-attn", "--device-map", "cuda:0"],
  ["YanweiLi/MGM-2B", "--use-flash-attn"],
  ["adept/fuyu-8b", "--device-map", "cuda:0", "--load-in-4bit"],
  ["adept/fuyu-8b", "--device-map", "cuda:0"],
  ["cognitivecomputations/dolphin-vision-72b", "--use-flash-attn", "--load-in-4bit"],
  ["cognitivecomputations/dolphin-vision-7b", "--use-flash-attn", "--load-in-4bit"],
  ["cognitivecomputations/dolphin-vision-7b", "--use-flash-attn"],
  ["echo840/Monkey", "--load-in-4bit"],
  ["echo840/Monkey"],
  ["echo840/Monkey-Chat", "--load-in-4bit"],
  ["echo840/Monkey-Chat"],
  ["failspy/Phi-3-vision-128k-instruct-abliterated-alpha", "--use-flash-attn", "--load-in-4bit"],
  ["failspy/Phi-3-vision-128k-instruct-abliterated-alpha", "--use-flash-attn"],
  ["internlm/internlm-xcomposer2d5-7b", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["internlm/internlm-xcomposer2d5-7b", "--use-flash-attn", "--device-map", "cuda:0"],
  ["internlm/internlm-xcomposer2-4khd-7b", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["internlm/internlm-xcomposer2-4khd-7b", "--use-flash-attn", "--device-map", "cuda:0"],
  ["internlm/internlm-xcomposer2-7b", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["internlm/internlm-xcomposer2-7b", "--use-flash-attn", "--device-map", "cuda:0"],
  ["internlm/internlm-xcomposer2-7b-4bit", "--use-flash-attn"],
  ["internlm/internlm-xcomposer2-vl-1_8b", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["internlm/internlm-xcomposer2-vl-1_8b", "--use-flash-attn", "--device-map", "cuda:0"],
  ["internlm/internlm-xcomposer2-vl-7b", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["internlm/internlm-xcomposer2-vl-7b", "--use-flash-attn", "--device-map", "cuda:0"],
  ["internlm/internlm-xcomposer2-vl-7b-4bit", "--use-flash-attn"],
  ["llava-hf/llava-1.5-13b-hf", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["llava-hf/llava-1.5-13b-hf", "--use-flash-attn", "--device-map", "cuda:0"],
  ["llava-hf/llava-1.5-7b-hf", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["llava-hf/llava-1.5-7b-hf", "--use-flash-attn", "--device-map", "cuda:0"],
  ["llava-hf/llava-v1.6-34b-hf", "--use-flash-attn", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-34b-hf", "--use-flash-attn"],
  ["llava-hf/llava-v1.6-mistral-7b-hf", "--use-flash-attn", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-mistral-7b-hf", "--use-flash-attn"],
  ["llava-hf/llava-v1.6-vicuna-13b-hf", "--use-flash-attn", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-vicuna-13b-hf", "--use-flash-attn"],
  ["llava-hf/llava-v1.6-vicuna-7b-hf", "--use-flash-attn", "--load-in-4bit"],
  ["llava-hf/llava-v1.6-vicuna-7b-hf", "--use-flash-attn"],
  ["microsoft/Florence-2-base-ft", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["microsoft/Florence-2-base-ft", "--use-flash-attn", "--device-map", "cuda:0"],
  ["microsoft/Florence-2-large-ft", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["microsoft/Florence-2-large-ft", "--use-flash-attn", "--device-map", "cuda:0"],
  ["microsoft/Phi-3-vision-128k-instruct", "--use-flash-attn", "--load-in-4bit"],
  ["microsoft/Phi-3-vision-128k-instruct", "--use-flash-attn"],
  ["openbmb/MiniCPM-Llama3-V-2_5", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["openbmb/MiniCPM-Llama3-V-2_5", "--use-flash-attn", "--device-map", "cuda:0"],
  ["openbmb/MiniCPM-V", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["openbmb/MiniCPM-V", "--use-flash-attn", "--device-map", "cuda:0"],
  ["openbmb/MiniCPM-V-2", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["openbmb/MiniCPM-V-2", "--use-flash-attn", "--device-map", "cuda:0"],
  ["qihoo360/360VL-8B", "--use-flash-attn", "--load-in-4bit"],
  ["qihoo360/360VL-8B", "--use-flash-attn"],
  ["qnguyen3/nanoLLaVA", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["qnguyen3/nanoLLaVA", "--use-flash-attn", "--device-map", "cuda:0"],
  ["qnguyen3/nanoLLaVA-1.5", "--use-flash-attn", "--device-map", "cuda:0", "--load-in-4bit"],
  ["qnguyen3/nanoLLaVA-1.5", "--use-flash-attn", "--device-map", "cuda:0"],
  ["qresearch/llama-3-vision-alpha-hf", "--device", "cuda:0", "--load-in-4bit"],
  ["qresearch/llama-3-vision-alpha-hf", "--device", "cuda:0"],
  ["tiiuae/falcon-11B-vlm", "--use-flash-attn", "--load-in-4bit"],
  ["tiiuae/falcon-11B-vlm", "--use-flash-attn"],
  ["togethercomputer/Llama-3-8B-Dragonfly-Med-v1", "--load-in-4bit"],
  ["togethercomputer/Llama-3-8B-Dragonfly-Med-v1"],
  ["togethercomputer/Llama-3-8B-Dragonfly-v1", "--load-in-4bit"],
  ["togethercomputer/Llama-3-8B-Dragonfly-v1"],
  ["vikhyatk/moondream2", "--use-flash-attn", "--load-in-4bit"],
  ["vikhyatk/moondream2", "--use-flash-attn"]
]
