version: '3.8'

# {
#   "nominatim-pino": "localhost:8080",
#   "timescaledb-pino": "localhost:5432",
#   "gotify-pino": "localhost:9090",
#   "realtime-pino": "localhost:8081",
#   "llamafile": "localhost:8082",
#   "whisper-streaming": "localhost:43007",
#   "openedai-vision": "localhost:5006"
# }

services:
  nominatim-pino:
    image: mediagis/nominatim:4.4
    container_name: nominatim-pino
    shm_size: '1gb'
    env_file:
      - ./.env
    volumes:
      - nominatim-data:/var/lib/postgresql/14/main
    ports:
      - "${NOMINATIM_PORT}:8080"
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:${NOMINATIM_PORT}/status || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s

  timescaledb-pino:
    env_file:
      - ./.env
    image: timescale/timescaledb-ha:pg16
    container_name: timescaledb-pino
    ports:
      - "5432:5432"
    volumes:
      - timescaledb-data:/home/postgres/pgdata/data
    restart: unless-stopped
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  gotify-pino:
    image: gotify/server
    container_name: gotify-pino
    ports:
      - 9090:80
    env_file:
      - ./.env
    volumes:
      - gotify-data:/app/data
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:80/health || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5
      
  subscriptions-pino:
    container_name: subscriptions-pino
    env_file:
      - ./.env
    build:
      context: .
      dockerfile: ./subscriptions/Dockerfile
    volumes:
      - ./subscriptions:/app/subscriptions
      - ./libraries:/app/libraries
    depends_on:
      timescaledb-pino:
        condition: service_healthy
      gotify-pino:
        condition: service_healthy
      nominatim-pino:
        condition: service_healthy
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "pidof python3.11 || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10

  scheduled-pino:
    container_name: scheduled-pino
    env_file:
      - ./.env
    build:
      context: .
      dockerfile: ./scheduled/Dockerfile
    volumes:
      - ./scheduled:/app/scheduled
    depends_on:
      timescaledb-pino:
        condition: service_healthy
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "pidof python3.11 || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10

  realtime-pino:
    container_name: realtime-pino
    env_file:
      - ./.env
    build:
      context: .
      dockerfile: ./realtime/Dockerfile
    volumes:
      - ./realtime:/app/realtime
    depends_on:
      timescaledb-pino:
        condition: service_healthy
      gotify-pino:
        condition: service_healthy
      whisper-pino:
        condition: service_healthy
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; import sys; sys.exit(0 if urllib.request.urlopen('http://localhost:${REALTIME_SERVER_PORT}/heartbeat').getcode() == 200 else 1)\""]
      interval: 5s
      timeout: 5s
      retries: 10
    ports:
      - "${REALTIME_SERVER_PORT}:${REALTIME_SERVER_PORT}"

  # llamafile-pino:
  #   container_name: llamafile-pino
  #   image: iverly/llamafile-docker:latest
  #   ports:
  #     - "8082:8080"
  #   volumes:
  #     - ./llamafile/model/Meta-Llama-3.1-8B.Q4_0.llamafile:/model
  #   networks:
  #     - pino-network
    # -ngl 9999 to enable GPU offloading

  whisper-pino:
    container_name: whisper-pino
    build:
      context: ./whisper_streaming
      dockerfile: Dockerfile
    ports:
      - "43007:43007"
    networks:
      - pino-network
    healthcheck:
      # test: ["CMD-SHELL", "python3 -c \"import socket; s = socket.socket(socket.AF_INET, socket.SOCK_STREAM); result = s.connect_ex(('localhost', 43007)); s.close(); exit(0 if result == 0 else 1)\""]
      # test: ["CMD-SHELL", "exit 0"]
      test: ["CMD-SHELL", "pidof python3.11 || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 15s # wait 15 seconds for the warm up, don't actually care about the health
    volumes:
      - ./whisper_streaming/models:/app/models
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  vision-pino:
    container_name: vision-pino
    build:
      context: ./openedai-vision
      dockerfile: Dockerfile
      args:
        - VERSION=latest
    image: ghcr.io/matatonic/openedai-vision
    env_file:
      - ./.env
    volumes:
      - ./openedai-vision/hf_home:/app/hf_home
      - ./openedai-vision/model_zoo:/app/model_zoo
      - ./openedai-vision/YanweiLi:/app/YanweiLi
      - ./openedai-vision/model_conf_tests.json:/app/model_conf_tests.json
    ports:
      - "5006:5006"
    networks:
      - pino-network
    healthcheck:
      test: ["CMD-SHELL", "pidof python || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 30
    command: ["python", "vision.py", "--model", "vikhyatk/moondream2"]

volumes:
  nominatim-data:
    driver: local
  timescaledb-data:
    driver: local
  gotify-data:
    driver: local

networks:
  pino-network:
    driver: bridge
